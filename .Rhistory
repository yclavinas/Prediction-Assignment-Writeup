data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainSmall <- data.frame(training[,grep('^IL',names(training))],training$diagnosis)
testSmall <- data.frame(testing[,grep('^IL',names(testing))],testing$diagnosis)
preProc <- preProcess(trainSmall[-13],method="pca",thres=.7)
trainPC <- predict(preProc,trainSmall[-13])
testPC <- predict(preProc,testSmall[-13])
modelFit <- train(trainSmall$training.diagnosis ~ ., method="glm", preProcess = c("pca", thres=.7), data=trainSmall)
getModelInfo())
getModelInfo()
modelFit <- train(trainSmall$training.diagnosis ~ ., method="svmLinearWeights2", preProcess = "pca", data=trainSmall)
modelFit <- train(trainSmall$training.diagnosis ~ ., method="lssvmLinear", preProcess = "pca", data=trainSmall)
modelFit <- train(trainSmall$training.diagnosis ~ ., method="brnn", preProcess = "pca", data=trainSmall)
modelFit <- train(trainSmall$training.diagnosis ~ ., method="brnn", preProcess = "pca", data=trainSmall)
modelFit <- train(trainSmall$training.diagnosis ~ ., method="earth", preProcess = "pca", data=trainSmall)
modelFit <- train(trainSmall$training.diagnosis ~ ., method="brnn", neurons=10, preProcess = "pca", data=trainSmall)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
suppressMessages(library(rattle))
install.packages('rattle')
install.packages('RGtk2')
library(pgmm)
data(olive)
olive = olive[, -1]
install.packages('pgmm')
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
model<-train(Area ~ ., data=olive, method="rpart")
predict(model, newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(ElemStatLearn)
install.packages('El')
install.packages('ElemStatLearn')
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
?predict
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
library(caret)
confusionMatrix(pred_rf, vowel.test$y)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)
confusionMatrix(pred_gbm, vowel.test$y)
combModFit <- train (y ~ . , data = predDF, method = "gam")
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
combModFit <- train (y ~ . , data = predDF, method = "gam")
confusionMatrix(
predict(vowel.fit.rf, vowel.test),
predict(vowel.fit.gbm, vowel.test)
)
confusionMatrix(
predict(pred_rf, vowel.test),
predict(pred_gbm, vowel.test)
)
confusionMatrix(
predict(mod_rf, vowel.test),
predict(mod_gbm, vowel.test)
)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(trainning)
str(training)
names(training)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
set.seed(62433)
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
set.seed(62433)
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
set.seed(62433)
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
confusionMatrix(mod_rf, testing$diagnosis)$overall[1]
confusionMatrix(mod_, testing$diagnosis)$overall[1]
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]# 0.804878
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)$overall[1]# 0.804878
set.seed(62433)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)$overall[1]# 0.804878
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(elasticnet)
install.packages("elasticnet")
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod_lasso <- train(diagnosis ~ ., data = training, method = "lasso")
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
plot.enet(mod_lasso$finalModel,
xvar="penalty", use.color=TRUE)
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages('forecast')
mod_ts <- bats(tstrain)
library(forecast)
mod_ts <- bats(tstrain)
tstrain = ts(training$visitsTumblr)
tstrain
mod_ts <- bats(training)
mod_ts <- bats(tstrain)
tstrain = ts(training$visitsTumblr)
mod_ts <- bats(tstrain)
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr &  testing$visitsTumblr < fcast$upper)/nrow(testing)
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
mod_ts <- bats(tstrain)
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr &  testing$visitsTumblr < fcast$upper)/nrow(testing)
library(lubridate) # For year() function below
library(forecast)
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
mod_ts <- bats(tstrain)
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
bats <- bats(tstrain)
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr &  testing$visitsTumblr < fcast$upper)/nrow(testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(3525)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
confusionMatrix(pred_svm, testing$CompressiveStrength)
# (1) Sensor on the Belt: discretization of the module of acceleration vector, variance of pitch, and variance of roll;
# (2) Sensor on the left thigh: module of acceleration vector, discretization, and variance of pitch;
# (3) Sensor on the right ankle: variance of pitch, and variance of roll;
# (4) Sensor on the right arm: discretization of the module of acceleration vector; From all sensors: average accele- ration and standard deviation of acceleration.
# C4.5 decision tree was used in connection with the AdaBoost ensemble method
# We used AdaBoost with 10 iterations and configured the C4.5 tree for a confidence factor of 0.25.
require(knitr)
require(caret)
require(rpart)
require(rpart.plot)
require(rattle)
require("RANN")
require("ada")
require("plyr")
require("corrplot")
require("randomForest")
training <- read.csv("data/traning.csv")
testing <- read.csv("data/testing.csv")
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5)]
preObj <- preProcess(training[,-length(training)],method=c("knnImpute"), thresh=0.9)
preObj2 <- predict(preObj, training[,-length(training)])
u
setwd(dir = "~/Documents/estudos/coursera/praticalML/")
training <- read.csv("data/traning.csv")
testing <- read.csv("data/testing.csv")
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5)]
preObj <- preProcess(training[,-length(training)],method=c("knnImpute"), thresh=0.9)
preObj2 <- predict(preObj, training[,-length(training)])
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
results_gbm_pca = train(training$classe ~., data=cleanData, method="gbm", trControl = controlGBM, verbose = FALSE))
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
results_gbm_pca = train(training$classe ~., data=cleanData, method="gbm", trControl = controlGBM, verbose = FALSE))
results_gbm_pca = train(training$classe ~., data=cleanData, method="gbm", trControl = controlGBM, verbose = FALSE)
results_gbm_pca$finalModel
results_rf_pca = train(training$classe ~., data=cleanData, method="rf",  trControl = controlRF,verbose = FALSE)
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
results_rf_pca = train(training$classe ~., data=cleanData, method="rf",  trControl = controlRF,verbose = FALSE)
test <- predict(preObj, testing[,-length(testing)])
testing <- read.csv("data/testing.csv")
test <- predict(preObj, testing[,-length(testing)])
testing <- testing[,-nearZeroVar(testing)]
testing <- testing[,-c(1,2,3,4,5)]
test <- predict(preObj, testing[,-length(testing)])
names(testing)
names(training)
names(testing)
testing <- read.csv("data/testing.csv")
testing$classe <- as.factor(testing$classe)
names(testing)
testing <- read.csv("data/testing.csv")
names(testing)
testing <- testing[,-nearZeroVar(testing)]
testing <- testing[,-c(1,2,3,4,5)]
test <- predict(preObj, testing[,-length(testing)])
training <- read.csv("data/traning.csv")
testing <- read.csv("data/testing.csv")
names(testing[1;5])
names(testing[1:5])
names(training[1:5])
testing <- testing[,-nearZeroVar(testing)]
testing <- testing[,-c(1,2,3,4,5)]
test <- predict(preObj, testing[,-length(testing)])
test <- predict(preObj, testing)
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
test <- predict(preObj, testing[,-length(testing)])
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
srt(inTrain)
str(inTrain)
names(inTrain)
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
training <- read.csv("data/traning.csv")
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5)]
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
names(testing) == names(training)
corMatrix <- cor(preObj2[,-length(preObj2)])
corrplot(corMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8, tl.col = rgb(0, 0, 0))
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
results_rf_pca = train(training$classe ~., data=cleanData, method="rf",  trControl = controlRF,verbose = FALSE)
test <- predict(preObj, testing[,-length(testing)])
confusionMatrix(testing$classe, predict(results_gbm_pca,test))
test <- predict(preObj, testing)
confusionMatrix(testing$classe, predict(results_rf_pca,test))
confusionMatrix(testing$classe, predict(results_gbm_pca,test))
confusionMatrix(testing$classe, predict(results_rf_pca,test))
test <- predict(preObj, testing[,-length(testing)])
confusionMatrix(testing$classe, predict(results_gbm_pca,test))
confusionMatrix(testing$classe, predict(results_rf_pca,test))
set.seed(301)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
results_gbm_pca = train(training$classe ~., data=cleanData, method="gbm", trControl = controlGBM, verbose = FALSE)
test <- predict(preObj, testing[,-length(testing)])
confusionMatrix(testing$classe, predict(results_gbm_pca,test))
confusionMatrix(testing$classe, predict(results_rf_pca,test))
set.seed(301)
set.seed(301)
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
results_rf_pca = train(training$classe ~., data=cleanData, method="rf",  trControl = controlRF,verbose = FALSE)
confusionMatrix(testing$classe, predict(results_gbm_pca,testing))
results_rf_pca$finalModel
results_gbm_pca$finalModel
results_gbm_pca
predictGBM <- predict(results_gbm_pca, newdata=testing)
test <- predict(preObj, testing[,-length(testing)])
confusionMatrix(testing$classe, predict(results_gbm_pca,testing))
confusionMatrix(testing$classe, predict(results_gbm_pca,test))
confusionMatrix(testing$classe, predict(results_rf_pca,test))
set.seed(301)
modelFit <- train(training$classe ~.,data=clean_data, method="knn")
modelFit <- train(training$classe ~.,data=cleanData, method="knn")
testing <- testing[,names(testing) %in% names(training)]
test <- predict(preObj, testing)
testing <- read.csv("data/testing.csv")
testing <- testing[,names(testing) %in% names(training)]
test <- predict(preObj, testing)
predict_result <- predict(modelFit, test)
predict_result
confusionMatrix(testing$classe, predict_result)
predict_result <- predict(controlRF, test)
predict_result <- predict(results_gbm_pca,test)
confusionMatrix(testing$classe, predict_result)
predict_result
results_rf_pca
predict_result <- predict(results_gbm_pca,test)
predict_result
predict_result <- predict(results_rf_pca,test)
predict_result
confusionMatrix(testing$classe, predict(results_gbm_pca,test))
test <- predict(preObj, testing[,-length(testing)])
modelFit <- train(training$classe ~.,data=cleanData, method="knn")
confusionMatrix(testing$classe, predict(modelFit,test))
testing <- training[-inTrain,]
i
test <- predict(preObj, testing[,-length(testing)])
confusionMatrix(testing$classe, predict(modelFit,test))
testingFile <- testingFile[,names(testingFile) %in% names(training)]
testingFile <- read.csv("data/testing.csv")
testingFile <- testingFile[,names(testingFile) %in% names(training)]
testFile <- predict(preObj, testing)
predict_result <- predict(modelFit,testFile)
testingFile <- read.csv("data/testing.csv")
testingFile <- testingFile[,names(testingFile) %in% names(training)]
testFile <- predict(preObj, testing)
testFile <- predict(preObj, testingFile)
predict_result <- predict(modelFit,testFile)
predict_result
modelFit$finalModel
training <- read.csv("data/traning.csv")
testing <- read.csv("data/testing.csv")
inTrain  <- createDataPartition(training$classe, p=0.7, list=FALSE)
TrainSet <- training[inTrain, ]
TestSet  <- training[-inTrain, ]
AllNA    <- sapply(TrainSet, function(x) mean(is.na(x))) > 0.95
TrainSet <- TrainSet[, AllNA==FALSE]
TestSet  <- TestSet[, AllNA==FALSE]
NZV <- nearZeroVar(TrainSet)
TrainSet <- TrainSet[, -NZV]
TestSet  <- TestSet[, -NZV]
inTrain  <- createDataPartition(training$classe, p=0.7, list=FALSE)
TrainSet <- training[inTrain, ]
TestSet  <- training[-inTrain, ]
NZV <- nearZeroVar(TrainSet)
TrainSet <- TrainSet[, -NZV]
TestSet  <- TestSet[, -NZV]
AllNA    <- sapply(TrainSet, function(x) mean(is.na(x))) > 0.95
TrainSet <- TrainSet[, AllNA==FALSE]
TestSet  <- TestSet[, AllNA==FALSE]
TrainSet <- TrainSet[, -(1:5)]
TestSet  <- TestSet[, -(1:5)]
set.seed(301)
modelFit2<- train(training$classe ~.,data=TrainSet, method="knn")
modelFit2<- train(classe ~.,data=TrainSet, method="knn")
confusionMatrix(testing$classe, predict(modelFit2,TestSet))
knitr::opts_chunk$set(echo = TRUE)
require("plyr")
require("corrplot")
require("randomForest")
setwd(dir = "~/Documents/estudos/coursera/praticalML/")
results_gbm_pca
confusionMatrix(testing$classe, predict(modelFit,test))
test <- predict(preObj, testing[,-length(testing)])
confusionMatrix(TestSet$classe, predict(modelFit2,TestSet))
knitr::opts_chunk$set(echo = TRUE)
require("plyr")
require("caret")
require("corrplot")
require("randomForest")
setwd(dir = "~/Documents/estudos/coursera/praticalML/")
corMatrix <- cor(training[,-length(training)])
preObj <- preProcess(training[,-length(training)],method=c("pca"), thresh=0.9)
corMatrix <- cor(preObj[,-length(preObj)])
corMatrix <- cor(preObj,training[,-length(training)])
preObj <- preProcess(training[,-length(training)],method=c("knnImpute"), thresh=0.9)
corMatrix <- cor(preObj, training[,-length(preObj)])
corMatrix <- cor(preObj, preObj[,-length(preObj)])
corMatrix <- cor(preObj[,-length(preObj)])
corMatrix <- cor(preObj[,-length(preObj)])
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute"), thresh=0.9)
corMatrix <- cor(preObj[,-length(preObj)])
length(preObj)
corMatrix <- cor(training[,-length(training)])
preObj2 <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute"), thresh=0.9)
corMatrix <- cor(preObj2[,-length(preObj2)])
class(preObj)
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
corMatrix <- cor(cleanData[,-length(cleanData)])
cleanData <- predict(preObj, training[,-length(training)])
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
training <- read.csv("data/traning.csv")
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5)]
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
preObj2 <- preProcess(training[,-length(training)],method=c("knnImpute"), thresh=0.9)
corMatrix <- cor(preObj2[,-length(preObj2)])
corMatrix <- cor(cleanData[,-length(cleanData)])
corrplot(corMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8, tl.col = rgb(0, 0, 0))
preObj2 <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute"), thresh=0.9)
corMatrix <- cor(preObj2[,-length(preObj2)])
knitr::opts_chunk$set(echo = TRUE)
require("plyr")
require("caret")
require("corrplot")
require("randomForest")
setwd(dir = "~/Documents/estudos/coursera/praticalML/")
# getting traning and testing data
if (!file.exists("data/traning.csv")){
url.traning <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url.traning, destfile = "data/traning.csv")
}
if (file.exists("data/traning.csv")){
training <- read.csv("data/traning.csv")
}
if (!file.exists("data/testing.csv")) {
url.testing <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url.testing, destfile = "data/testing.csv")
}
if (file.exists("data/traning.csv")){
testingFile <- read.csv("data/testing.csv")
}
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5)]
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
modelFit <- train(training$classe ~.,data=cleanData, method="knn")
