set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainSmall <- data.frame(training[,grep('^IL',names(training))],training$diagnosis)
testSmall <- data.frame(testing[,grep('^IL',names(testing))],testing$diagnosis)
preProc <- preProcess(trainSmall[-13],method="pca",thres=.7)
trainPC <- predict(preProc,trainSmall[-13])
testPC <- predict(preProc,testSmall[-13])
modelFit <- train(trainSmall$training.diagnosis ~ ., method="glm", preProcess = c("pca", thres=.7), data=trainSmall)
getModelInfo())
getModelInfo()
modelFit <- train(trainSmall$training.diagnosis ~ ., method="svmLinearWeights2", preProcess = "pca", data=trainSmall)
modelFit <- train(trainSmall$training.diagnosis ~ ., method="lssvmLinear", preProcess = "pca", data=trainSmall)
modelFit <- train(trainSmall$training.diagnosis ~ ., method="brnn", preProcess = "pca", data=trainSmall)
modelFit <- train(trainSmall$training.diagnosis ~ ., method="brnn", preProcess = "pca", data=trainSmall)
modelFit <- train(trainSmall$training.diagnosis ~ ., method="earth", preProcess = "pca", data=trainSmall)
modelFit <- train(trainSmall$training.diagnosis ~ ., method="brnn", neurons=10, preProcess = "pca", data=trainSmall)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
suppressMessages(library(rattle))
install.packages('rattle')
install.packages('RGtk2')
library(pgmm)
data(olive)
olive = olive[, -1]
install.packages('pgmm')
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
model<-train(Area ~ ., data=olive, method="rpart")
predict(model, newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(ElemStatLearn)
install.packages('El')
install.packages('ElemStatLearn')
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
?predict
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
library(caret)
confusionMatrix(pred_rf, vowel.test$y)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)
confusionMatrix(pred_gbm, vowel.test$y)
combModFit <- train (y ~ . , data = predDF, method = "gam")
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
combModFit <- train (y ~ . , data = predDF, method = "gam")
confusionMatrix(
predict(vowel.fit.rf, vowel.test),
predict(vowel.fit.gbm, vowel.test)
)
confusionMatrix(
predict(pred_rf, vowel.test),
predict(pred_gbm, vowel.test)
)
confusionMatrix(
predict(mod_rf, vowel.test),
predict(mod_gbm, vowel.test)
)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(trainning)
str(training)
names(training)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
set.seed(62433)
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
set.seed(62433)
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
set.seed(62433)
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
confusionMatrix(mod_rf, testing$diagnosis)$overall[1]
confusionMatrix(mod_, testing$diagnosis)$overall[1]
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]# 0.804878
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)$overall[1]# 0.804878
set.seed(62433)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)$overall[1]# 0.804878
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(elasticnet)
install.packages("elasticnet")
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod_lasso <- train(diagnosis ~ ., data = training, method = "lasso")
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
plot.enet(mod_lasso$finalModel,
xvar="penalty", use.color=TRUE)
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages('forecast')
mod_ts <- bats(tstrain)
library(forecast)
mod_ts <- bats(tstrain)
tstrain = ts(training$visitsTumblr)
tstrain
mod_ts <- bats(training)
mod_ts <- bats(tstrain)
tstrain = ts(training$visitsTumblr)
mod_ts <- bats(tstrain)
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr &  testing$visitsTumblr < fcast$upper)/nrow(testing)
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
mod_ts <- bats(tstrain)
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr &  testing$visitsTumblr < fcast$upper)/nrow(testing)
library(lubridate) # For year() function below
library(forecast)
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
mod_ts <- bats(tstrain)
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
bats <- bats(tstrain)
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr &  testing$visitsTumblr < fcast$upper)/nrow(testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(3525)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
confusionMatrix(pred_svm, testing$CompressiveStrength)
# (1) Sensor on the Belt: discretization of the module of acceleration vector, variance of pitch, and variance of roll;
# (2) Sensor on the left thigh: module of acceleration vector, discretization, and variance of pitch;
# (3) Sensor on the right ankle: variance of pitch, and variance of roll;
# (4) Sensor on the right arm: discretization of the module of acceleration vector; From all sensors: average accele- ration and standard deviation of acceleration.
# C4.5 decision tree was used in connection with the AdaBoost ensemble method
# We used AdaBoost with 10 iterations and configured the C4.5 tree for a confidence factor of 0.25.
require(knitr)
require(caret)
require(rpart)
require(rpart.plot)
require(rattle)
require("RANN")
require("plyr")
require("corrplot")
require("randomForest")
setwd(dir = "~/Documents/estudos/coursera/praticalML/")
training <- read.csv("data/traning.csv")
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
dim(preObj)
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
test <- predict(preObj, testing[,-length(testing)])
dim(preObj)
names(preObj)
str(preObj)
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
names(training)
names(training[,length(training)])
names(training[length(training)])
cleanData <- predict(preObj, preObj[,-length(preObj)])
cleanData <- predict(preObj, training[,-length(training)])
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
clean_data <- predict(preObj,training[,-length(training)])
library(caret)
set.seed(12463)
training <- read.csv("pml-training.csv", stringsAsFactors=FALSE)
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5,6,7)]
library(caret)
set.seed(12463)
training <- read.csv("data/traning.csv")
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5,6,7)]
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
clean_data <- predict(preObj,training[,-length(training)])
training <- training[,-c(1,2,3,4,5,6,7)]
training <- read.csv("data/traning.csv")
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5)]
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
clean_data <- predict(preObj,training[,-length(training)])
library(caret)
set.seed(12463)
training <- read.csv("data/traning.csv")
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5)]
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
clean_data <- predict(preObj,training[,-length(training)])
training <- read.csv("data/traning.csv")
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5)]
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
test <- predict(preObj, testing[,-length(testing)])
knitr::opts_chunk$set(echo = TRUE)
require("plyr")
require("caret")
require("corrplot")
require("randomForest")
setwd(dir = "~/Documents/estudos/coursera/praticalML/")
# getting traning and testing data
if (!file.exists("data/traning.csv")){
url.traning <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url.traning, destfile = "data/traning.csv")
}
if (file.exists("data/traning.csv")){
training <- read.csv("data/traning.csv")
}
if (!file.exists("data/testing.csv")) {
url.testing <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url.testing, destfile = "data/testing.csv")
}
if (file.exists("data/traning.csv")){
testingFile <- read.csv("data/testing.csv")
}
knitr::opts_chunk$set(echo = TRUE)
require("plyr")
require("caret")
require("corrplot")
require("randomForest")
setwd(dir = "~/Documents/estudos/coursera/praticalML/")
# getting traning and testing data
if (!file.exists("data/traning.csv")){
url.traning <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url.traning, destfile = "data/traning.csv")
}
if (file.exists("data/traning.csv")){
training <- read.csv("data/traning.csv")
}
if (!file.exists("data/testing.csv")) {
url.testing <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url.testing, destfile = "data/testing.csv")
}
if (file.exists("data/traning.csv")){
testingFile <- read.csv("data/testing.csv")
}
str(training)
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5)]
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
test <- predict(preObj, testing[,-length(testing)])
set.seed(301)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
results_gbm_pca = train(training$classe ~., data=cleanData, method="gbm", trControl = controlGBM, verbose = FALSE)
cm_gbm <- confusionMatrix(testing$classe, predict(results_gbm_pca,test))
set.seed(301)
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
results_rf_pca = train(training$classe ~., data=cleanData, method="rf",  trControl = controlRF,verbose = FALSE)
cm_rf <- confusionMatrix(testing$classe, predict(results_rf_pca,test))
set.seed(301)
modelFit <- train(training$classe ~.,data=cleanData, method="knn")
cm_knn <- confusionMatrix(testing$classe, predict(modelFit,test))
Random Forest : ```{r}cm_rf$accuracy``` KNN : ```{r}cm_knn$accuracy``` GBM : ```{r}cm_gbm$accuracy```
Random Forest : `r cm_rf$accuracy` KNN : `r cm_knn$accuracy` GBM : `r cm_gbm$accuracy` In that case, the Random Forest model will be applied to predict the 20 quiz results (testing dataset) as shown below.
set.seed(301)
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
modelFit <- train(training$classe ~.,data=cleanData, method="knn")
cm_knn
cm_rf
cm_gbm
testingFile <- testingFile[,names(testingFile) %in% names(training)]
test <- predict(preObj, testingFile)
predict_result <- predict(modelFit,test)
testingFile <- testingFile[,names(testingFile) %in% names(training)]
test <- predict(preObj, testingFile)
predict_result <- predict(modelFit, test)
names(testingFile)
testingFile <- testingFile[,names(testingFile) %in% names(training)]
names(testingFile)
testingFile <- read.csv("data/testing.csv")
names(testingFile)
names(training)
names(training) == "classe"
sum(names(training) == "classe"_
sum(names(training) == "classe")
sum(names(testingFile) == "classe")
names(testingFile) %in% names(training)
Random Forest : `r cm_rf$accuracy` KNN : `r cm_knn$accuracy` GBM : `r cm_gbm$accuracy` In that case, the Random Forest model will be applied to predict the 20 quiz results (testing dataset) as shown below.
test <- predict(preObj, testingFile)
test <- predict(preObj, testingFile[,names(testingFile) %in% names(training)])
predict_result <- predict(modelFit,test)
modelFit$finalModel
results_knn_pca <- train(training$classe ~.,data=cleanData, method="knn")
knitr::opts_chunk$set(echo = TRUE)
require("plyr")
require("caret")
require("corrplot")
require("randomForest")
setwd(dir = "~/Documents/estudos/coursera/praticalML/")
# getting traning and testing data
if (!file.exists("data/traning.csv")){
url.traning <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url.traning, destfile = "data/traning.csv")
}
if (file.exists("data/traning.csv")){
training <- read.csv("data/traning.csv")
}
if (!file.exists("data/testing.csv")) {
url.testing <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url.testing, destfile = "data/testing.csv")
}
if (file.exists("data/traning.csv")){
testingFile <- read.csv("data/testing.csv")
}
training$classe <- as.factor(training$classe)
training <- training[,-nearZeroVar(training)]
training <- training[,-c(1,2,3,4,5)]
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training <- training[inTrain,]
testing <- training[-inTrain,]
preObj <- preProcess(training[,-length(training)],method=c("center", "scale", "knnImpute", "pca"), thresh=0.9)
cleanData <- predict(preObj, training[,-length(training)])
test <- predict(preObj, testing[,-length(testing)])
results_knn_pca <- train(training$classe ~.,data=cleanData, method="knn")
cm_knn <- confusionMatrix(testing$classe, predict(modelFit,test))
cm_knn <- confusionMatrix(testing$classe, predict(modelFit,results_knn_pca))
cm_knn <- confusionMatrix(testing$classe, predict(modelFit,results_knn_pca))
cm_knn <- confusionMatrix(testing$classe, predict(modelFit,results_knn_pca))
cm_rf <- confusionMatrix(testing$classe, predict(results_rf_pca,test))
set.seed(301)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
results_gbm_pca = train(training$classe ~., data=cleanData, method="gbm", trControl = controlGBM, verbose = FALSE)
cm_gbm <- confusionMatrix(testing$classe, predict(results_gbm_pca,test))
set.seed(301)
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
results_rf_pca = train(training$classe ~., data=cleanData, method="rf",  trControl = controlRF,verbose = FALSE)
cm_rf <- confusionMatrix(testing$classe, predict(results_rf_pca,test))
set.seed(301)
results_knn_pca <- train(training$classe ~.,data=cleanData, method="knn")
cm_knn <- confusionMatrix(testing$classe, predict(modelFit,results_knn_pca))
cm_rf <- confusionMatrix(testing$classe, predict(results_rf_pca,test))
cm_rf
cm_knn
cm_knn <- confusionMatrix(testing$classe, predict(modelFit,results_knn_pca))
cm_knn <- confusionMatrix(testing$classe, predict(results_knn_pca,test))
cm_knn
testingFile <- testingFile[,names(testingFile) %in% names(training)]
test <- predict(preObj, testingFile[,names(testingFile) %in% names(training)])
predict_result <- predict(modelFit,test)
predict_result <- predict(results_knn_pca,test)
predict_result
predict_result[1]
predict_result[2]
predict_result[3]
predict_result[5]
predict_result[4]
predict_result[6]
predict_result[7]
predict_result[8]
predict_result[9]
predict_result[10]
predict_result[11]
predict_result[12]
predict_result[13]
predict_result[14]
predict_result[15]
predict_result[16]
predict_result[17]
predict_result[18]
predict_result[19]
predict_result[20]
predict_result[21]
predict_result[3]
predict_result <- predict(results_rf_pca,test)
results_rf_pca[3]
predict_result[3]
predict_result[4]
cm_knn$overall
cm_knn$overall[1]
